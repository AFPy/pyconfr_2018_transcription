

Visualising the world  of competitive  programming with  Python  Anuj Menta


14:32:000600:000600_1 : 14:31:34:737: Hi hello veryone . 1
14:32:000601:000601_2 : 14:32:15:885: I'm from India so I'll be talking about visualising the role of computer programming . 2
14:32:000602:000602_3 : 14:32:23:049: T's been about 5 years since I first told my programming my first fighting coats and I'm a mathematics major from any material technology India I work with American Express for any other . 3
14:33:000603:000603_4 : 14:32:36:215: And I am very passionate about speak to me so that is like solving the likely be played on with puzzles like Rubik's Cube and it takes about 10 to 15 seconds to sort . 4
14:33:000604:000604_1 : 14:32:48:358: So a little bit about the talk the talk is going to be divided into 2 parts where I'll be talking about the entire process I will be away the prodigal son shirts because in . 1
14:34:000605:000605_3 : 14:33:03:485: involved in projects maybe I didn't want scraping a website Gathering And I'll be talking about one for the project was it what is competitive programming so has anyone worked with competitive programming any computer programmers ok great so I just give you a brief about computer programming computer programming is Vicks objective and achieving the objective a specific and things like the number of iterations but the program has to exist . 3
14:34:000606:000606_0 : 14:33:43:766: Specific amount of time LED ceiling one second or 3 seconds depending on the programming language using so the website I have used a Sky code for sis.com it is a online programming contest very have questions and that this letter structure of the website you can use any language you want there are different types of questions like that scene dynamic programming greedy add . 4
14:34:000607:000607_1 : 14:34:08:888: Just basic math or implementation and it also has a lot of people solving the question so for example if it for a b c d e f that is one contest which is conducted globally and I just a number of people website I have used to screen so the data set is basically programs people have written so there are actually about . 1
14:35:000608:000608_2 : 14:34:40:019: 500k Programmes that people have written in about 16 different languages java c c python and everything and the . 2
14:35:000609:000609_3 : 14:34:51:150: For about 3500 questions and like for example you can see different type of questions the implementation dynamic programming greedy brute force so the total number of type of question is 5260 and submission sample 30 countries to this is a data said we have used for the entire analysis and I have performed a few visualisations and I also give you the actual object . 3
14:36:000610:000610_0 : 14:35:17:323: Entire project so the project started off with trying to distinguish the way beginners code in Python with respect to expert programming experience programme objectives of the project and have read it a few visualisations so the first and foremost is the number of the years the person has been coding till now so this is basically the chart as you can see
14:36:000611:000611_1 : 14:35:47:467: So it's it's kind of beginning for that the people who come onto the platform to learn computer programming usually about 2 years and it goes on like the harder it gets so it's like they're very large number of people stick to 6 to 7 years and they are mostly language you can call experienced programmers . 1
14:36:000612:000612_0 : 14:36:13:594: This is a complex visualisation of this is basically language used for solving the problem was is the type of the problem so so this is like implementation dynamic programming greedy math and brute force so if you can see I usually Python is not the best language to use to solve questions in competitive programming so it is usually in
14:37:000613:000613_3 : 14:36:40:718: Dial equations in computer programming in that is one area where Python is still working on so . 3
14:37:000614:000614_4 : 14:36:50:857: Is the rating of a user so every user has a particular ratings based on the number of questions is able to solve in a contest so this is simply the number of competitors available to solve a question what is the rating of the question which belongs . 4
14:37:000615:000615_1 : 14:37:08:997: So this is more like if a question is difficult then own we can only see people at a higher rating serving this is 289 so people would rating of 2500 to 3000 questions with obvious . 1
14:38:000616:000616_2 : 14:37:29:135: Evolution of language over years I'm only compared to languages Python Java and C as you can see is used by about 80/:/ of the programme was on the platform python and Java about to 15/:/ . 2
14:38:000617:000617_0 : 14:37:45:274: Now this is the average rating of one particular category of questions let's say we pick up dynamic programming so the average rating of users solving a particular type of question has been decreasing over the years which goes on to say that more and more people are trying to sort different difficult questions and the questions are
14:38:000618:000618_4 : 14:38:11:455: Easy enough we can see that more people are trying to solve the questions in different areas on . 4
14:39:000619:000619_1 : 14:38:19:497: So this is simply trying to see which categories can be ranked as the most difficult categories so if you are fast fourier transform our floors are one of the most difficult questions in computer programming so this is simply the average rating of all the uses this solve this paritcular kind of questions . 1
14:39:000620:000620_3 : 14:38:41:646: Oh yes so this is a kind of My Favorites of this is the number of lines of programming and this visualisation specific only to buy them obviously this is a number of lines of code is used against his rating so this goes on to say that experienced programmers time to get things done in less number of lines of code come by 2 List comprehensions that basically takes one line compared to go for loop which is written in at least three or four lines so that is kind of word this observation is . 3
14:39:000621:000621_4 : 14:39:19:127: demographics . 4
14:39:000622:000622_1 : 14:39:22:264: Bad Farm has the highest number of users from India and China Joshua validation is it but the highest rating age rating is the average of the top 100 users from a country so that is how it's it's ranks so so basically this analysis has been performed on a fertility describe myself so this is 500000 randomly sample code . 1
14:40:000623:000623_2 : 14:39:51:427: Million codes on the platform . 2
14:40:000624:000624_3 : 14:39:54:565: Would you do that and I only had to do this is on my laptop so I won't I randomly sampled them to obtain a 500000 sample of programs and then be analysis is performed at . 3
14:40:000625:000625_4 : 14:40:07:686: Briefly over the web scraping process I've used and how the pipeline was constructed like which website how do you choose a website or even after you choose your website how do you actually get the right elements so has anyone use web scraping before in their job in any time a couple of France . 4
14:41:000626:000626_1 : 14:40:27:822: Meaning meaningful information from any website you would want b dandelions website e-commerce website taxi aggregator so everyone needs are too late let's even if I want to see . 1
14:41:000627:000627_0 : 14:40:42:962: Play some comedy on Amazon it would be way it would make my life easier to just data scraper which hello to me like give me an alarm of the prize every day so it is a very simple escape that's the most basic implementation so if you can see you are so. libraries which I usually use in Python scraping beautifulsoup scrapy and requests . 2
14:41:000628:000628_3 : 14:41:08:102: selenium is a browser automation to it's not usually used for web scraping but that's kind of a hack to scrape websites which have dynamic content loaded . 3
14:42:000629:000629_4 : 14:41:19:241: So are this is kind of the entire pipeline which subject of us to distinguish dim the lights for grammar is experienced programmers and then choosing the right outside so this is what are soda multiple websites which have computer programming like Code forces top code and stuff like that forces has every program written by a user publicly available so every other . 4
14:42:000630:000630_1 : 14:41:47:421: Have you the other users programs publicly available so this was about said I could choose and you should also try to make the website multiple times and see also for example of you website are not really friendly so they have a robot txt file which says that you're not allowed to scrape this particular section of the website you should be checking these prior to your exercice. 1
14:43:000631:000631_2 : 14:42:10:546: some websites have a limit rate let's see if we only allow 40 to 50 degrees and minutes so if you're planning to scrape on Million Voices it's going to take you ages so unless you use proxies to use my life assessing so these Are a Few parameters you need to see when you are trying to choose a website how friendly is the website or stuff like that abuse online . 2
14:43:000632:000632_0 : 14:42:32:673: It's such a big down to a very simple structure example user rating the place from where the user is how many years should be so different. They don't you don't get all the information in one API call or one user request you need to get them differently separately so let's say you first axis or users rating then you'll see all the questions he has sold and then you try to figure out . 3
14:43:000633:000633_4 : 14:42:59:786: Is the category of the question being referred to in this context . 4
14:43:000634:000634_0 : 14:43:06:927: Different Pieces of information you need to gather and then put them together but also are the screen free by trade with me in that for example let's say you will come across a section which is Michelle been blocked let's say you've scraped continuously for a few hours and then use your phone as you go to Sierra from the website saying that you're not allowed to scrap the website anymore.
14:44:000635:000635_2 : 14:43:26:116: So you then have to see if you just got a temporary block or you need to see if you if it's just your company or trying to fetch or you're just tried to find a workaround or something like that so yes group feedback in nitrate and then putting the pieces together you now have a meaningful you have meaningful information now lets a user or this questions and for every questions . 2
14:44:000636:000636_3 : 14:43:49:225: The time it is taken to execute the language is returning old is metadata is not connecting after you break it down script separately and then put it together . 3
14:44:000637:000637_4 : 14:44:01:366: So now you have the data you need To make the visualisations are the NRA so she would like to do for example business it can be used to predict things like that so can you have a you have 10 lines of Python let's see you need to see if any of the combination of lines can be replaced by a function in Wales in some libraries Les you're using a sorting function which oil which is already there in Python to sort . 4
14:45:000638:000638_1 : 14:44:26:492: So if someone is writing the code for bubble sort out some sorting and get your code should be able to predict and the pea chunk of code which is doing that so busy that it would be an excellent training set for those kind of France right you can go on to be visualisations and predictions so yeah . 1
14:45:000639:000639_2 : 14:44:49:641: A small tip something which I find very useful when I'm doing web scraping so this is basically simply using multi processing and this is like so basically this this is he likes of course which you need to know and I to make your script functions by Lily . 2
14:45:000640:000640_3 : 14:45:09:771: ELO Billy Joel My Life assessing and this is so you just have a list of you are those which you need to scrape and then you have a function which makes a browser request and get you the information you require this is simply the function and a list of . 3
14:45:000641:000641_0 : 14:45:24:921: Different processes but it depends on your computer or the server you are using to scream because there is something called of global. I don't remember yes . 4
14:45:000642:000642_1 : 14:45:37:070: Is a battle bot fighting against this is . 1
14:46:000643:000643_2 : 14:45:42:209: Discord might actually help me a lot when I was doing any scraping exercice . 2
14:46:000644:000644_3 : 14:45:48:351: Let me know when are the next late I've been there a few practices which we usually call ethical practices by me do not overload the service like I could have always . 3
14:46:000645:000645_1 : 14:46:00:486: A million requests a second by using GPUs a service but that actually damage the website in a few cases so you should not be very aggressive try to keep it keep the limits very low so that the functionality of the site is not disturb and yes I mean I usually use of your data such as like use Instax they're really basically this is just to organise you Connection in the between you have a backup and stuff like that when is an aggressive hits . 1
14:47:000646:000646_2 : 14:46:32:285: Also that the one thing which was really handy was using no sequel databases like I use mongodb to store all the data scrape because when I'm scraping the data I don't know what I might be needing in the future let's I'm just writing a script to get all user ratings but now I find ok if I had the country of the user . 2
14:47:000647:000647_0 : 14:46:55:421: Leave my nose is so in that case if you just have to have already died on d mannose equally as you don't need to organise a such as I so for those who know don't know about no sequelitis they do not have a predefined schema like you have to have an idea then our users and then I using it you can just dump any type of
14:47:000648:000648_4 : 14:47:19:533: Because scraping needs a dynamic like for example if you're breaking it down all the trees it wouldn't have the same schema if you need SQL you'll have to make 3 different databases and then join them again so it's so I usually use to . 4
14:48:000649:000649_1 : 14:47:39:645: I just dump everything and then after I have already tried this tried to clean the redial make sense of I mean I just tried to excite all the features that require . 1
14:48:000650:000650_2 : 14:47:50:463: So I think that is it from my side I'll be really happy to take a few questions if you have some time thank you . 2
14:48:000651:000651_4 : 14:48:08:548: Yorkshire . 4
14:48:000652:000652_1 : 14:48:12:674: So it is question is how do you find out how friendly are website is for sleeping late how many quests can you make in a minute so it's usually . 1
14:49:000653:000653_2 : 14:48:33:813: Keep the car running and your if your blood after a minute or a few minutes see you do it again let's say you repeat the exercise multiple times just see I usually use 50 requested which is kind of safe and not very slow but it depends on the website . 2
14:51:000654:000654_3 : 14:48:50:954: When actually me Liverpool missions to scrape the website so that there's no issue by the US open the website but you can keep . 3
14:56:000655:000655_4 : 14:49:03:082: Ok thank you thank you so much thank you . 4

